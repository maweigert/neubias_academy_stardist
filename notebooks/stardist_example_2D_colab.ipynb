{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of stardist_example_2D_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iOe5g3bvSuJu",
        "sEU15_9zSf6d",
        "JwO371VFSf61",
        "W9i_Uc0Vhkmo"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaWMKwiySlW_"
      },
      "source": [
        "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maweigert/neubias_academy_stardist/blob/master/notebooks/stardist_example_2D_colab.ipynb)\n",
        "\n",
        "# Demo: Stardist custom training workflow (2D)\n",
        "\n",
        "\n",
        "To run the workflow on your own workstation/data, consider using our jupyter notebooks:  \n",
        "https://github.com/mpicbg-csbd/stardist/tree/master/examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOe5g3bvSuJu"
      },
      "source": [
        "# 0. Installation and preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V38hQNSS-vu"
      },
      "source": [
        "1. Set the google runtime to GPU (\"Runtime->Change runtime type\" select GPU)\n",
        "2. Install tensorflow (< version 2 for now)\n",
        "3. Install stardist\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_pJgAG0TgZW",
        "collapsed": true,
        "outputId": "18ad3f2a-8e6d-4c9a-bd14-b1d8c5465704"
      },
      "source": [
        "!pip install stardist"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stardist in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from stardist) (0.16.2)\n",
            "Requirement already satisfied: csbdeep>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from stardist) (0.6.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from stardist) (0.51.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->stardist) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->stardist) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->stardist) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->stardist) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->stardist) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->stardist) (2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from csbdeep>=0.6.0->stardist) (1.19.5)\n",
            "Requirement already satisfied: keras<2.4,>=2.1.2 in /tensorflow-1.15.2/python3.7 (from csbdeep>=0.6.0->stardist) (2.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from csbdeep>=0.6.0->stardist) (1.15.0)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from csbdeep>=0.6.0->stardist) (2021.3.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from csbdeep>=0.6.0->stardist) (4.41.1)\n",
            "Requirement already satisfied: h5py<3 in /usr/local/lib/python3.7/dist-packages (from csbdeep>=0.6.0->stardist) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->stardist) (54.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->stardist) (0.34.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->stardist) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->stardist) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->stardist) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->stardist) (2.8.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->stardist) (4.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras<2.4,>=2.1.2->csbdeep>=0.6.0->stardist) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras<2.4,>=2.1.2->csbdeep>=0.6.0->stardist) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras<2.4,>=2.1.2->csbdeep>=0.6.0->stardist) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US4nq_f2Sf6a"
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "from tifffile import imread\n",
        "from csbdeep.utils import Path, download_and_extract_zip_file, normalize\n",
        "\n",
        "from stardist.matching import matching_dataset\n",
        "from stardist import fill_label_holes, random_label_cmap, relabel_image_stardist, calculate_extents, gputools_available, _draw_polygons\n",
        "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
        "\n",
        "np.random.seed(42)\n",
        "lbl_cmap = random_label_cmap()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEU15_9zSf6d"
      },
      "source": [
        "# 1. Data\n",
        "\n",
        "This section demonstrates how the training data for *StarDist* should look like and whether the annotated objects can be appropriately described by star-convex polygons. \n",
        "\n",
        "The training data that needs to be provided for StarDist consists of corresponding pairs of raw images and pixelwise annotated ground truth images (masks), where every pixel has a unique integer value indicating the object id (or 0 for background). \n",
        "\n",
        "\n",
        "If you want to use your own data, you would need to \n",
        "\n",
        "1. Create a folder (e.g. \"mydata\") that includes the images and label masks for the training and test cases. The folder should have the following structure:\n",
        "\n",
        "```\n",
        "data\n",
        " |-mydata\n",
        " | |-train\n",
        " | | |-images\n",
        " | | | | image1.tif\n",
        " | | | | image2.tif \n",
        " | | | | ...\n",
        " | | |-masks\n",
        " | | | | mask1.tif\n",
        " | | | | mask2.tif \n",
        " | | | | ... \n",
        " | |-test\n",
        " | | |-images\n",
        " | | | | ...\n",
        " | | |-masks\n",
        " | | | | ...\n",
        " ```\n",
        "\n",
        "2. Upload this data to your google drive \n",
        "\n",
        "3. Mount your google drive \n",
        "\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/My\\ Drive/\n",
        "```\n",
        "\n",
        "4. Change the appropriate folder names below to the ones on your google drive.\n",
        "\n",
        "\n",
        "For this demo we will download the file `dsb2018.zip` that contains the respective train and test images with associated ground truth labels as used in [our paper](https://arxiv.org/abs/1806.03535).\n",
        "They are a subset of the `stage1_train` images from the Kaggle 2018 Data Science Bowl, which are [available in full](https://data.broadinstitute.org/bbbc/BBBC038/) from the [Broad Bioimage Benchmark Collection](https://data.broadinstitute.org/bbbc/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnsO-gPRSf6e",
        "outputId": "388864ab-8144-4a3b-b1fd-e25aeefce8c3"
      },
      "source": [
        "download_and_extract_zip_file(\n",
        "    url       = 'https://github.com/mpicbg-csbd/stardist/releases/download/0.1.0/dsb2018.zip',\n",
        "    targetdir = 'data',\n",
        "    verbose   = 1,\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files found, nothing to download.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B06g4tSPUMtk",
        "outputId": "9af06caf-e175-4f93-d38f-cd894b46d749"
      },
      "source": [
        "!find data -type d | sed -e \"s/[^-][^\\/]*\\// |/g\" -e \"s/|\\([^ ]\\)/|-\\1/\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\n",
            " |-dsb2018\n",
            " | |-train\n",
            " | | |-images\n",
            " | | |-masks\n",
            " | |-test\n",
            " | | |-images\n",
            " | | |-masks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKBWBJ-QSf6h",
        "outputId": "a4610a80-fb04-4071-e525-d8ac3e82c05f"
      },
      "source": [
        "fX = sorted(Path('data/dsb2018/train/images/').glob('*.tif'))\n",
        "fY = sorted(Path('data/dsb2018/train/masks').glob('*.tif'))\n",
        "print(f\"found {len(fX)} training images and {len(fY)} training masks\")\n",
        "assert all(Path(x).name==Path(y).name for x,y in zip(fX,fY))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found 447 training images and 447 training masks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTs--gG2Sf6j"
      },
      "source": [
        "Load only a small subset for display"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAoUNkj3Sf6k"
      },
      "source": [
        "fX_small, fY_small = fX[:10], fY[:10]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0KznkMbSf6m"
      },
      "source": [
        "X_small = list(map(imread,map(str,fX_small)))\n",
        "Y_small = list(map(imread,map(str,fY_small)))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6HBW-RsSf6n"
      },
      "source": [
        "## Example image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyDOaaUtSf6o"
      },
      "source": [
        "i = min(4, len(X_small)-1)\n",
        "img, lbl = X_small[i], fill_label_holes(Y_small[i])\n",
        "assert img.ndim in (2,3)\n",
        "img = img if img.ndim==2 else img[...,:3]\n",
        "# assumed axes ordering of img and lbl is: YX(C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qurOFQSMSf6q"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(121); plt.imshow(img,cmap='gray');   plt.axis('off'); plt.title('Raw image')\n",
        "plt.subplot(122); plt.imshow(lbl,cmap=lbl_cmap, interpolation=\"nearest\"); plt.axis('off'); plt.title('GT labels (mask)')\n",
        "None;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB0MYufYSf6s"
      },
      "source": [
        "## Fitting ground-truth labels with star-convex polygons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMc-Gl5lToSk"
      },
      "source": [
        "n_rays = [2**i for i in range(2,8)]\n",
        "print(n_rays)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtVJWwb1T00w"
      },
      "source": [
        "### Example image reconstructed with various number of rays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqnrU9DuT1i3"
      },
      "source": [
        "fig, ax = plt.subplots(2,3, figsize=(12,8))\n",
        "for a,r in zip(ax.flat,n_rays):\n",
        "    a.imshow(relabel_image_stardist(lbl, n_rays=r), cmap=lbl_cmap, interpolation=\"nearest\")\n",
        "    a.set_title('Reconstructed (%d rays)' % r)\n",
        "    a.axis('off')\n",
        "plt.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNQweGV9TsRR"
      },
      "source": [
        "#### Mean IoU for different number of rays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPZAInhNSf6t"
      },
      "source": [
        "scores = []\n",
        "for r in tqdm(n_rays):\n",
        "    Y_reconstructed = [relabel_image_stardist(lbl, n_rays=r) for lbl in Y_small]\n",
        "    mean_iou = matching_dataset(Y_small, Y_reconstructed, thresh=0, show_progress=False).mean_true_score\n",
        "    scores.append(mean_iou)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tBgKQijSf6u"
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(n_rays, scores, 'o-')\n",
        "plt.xlabel('Number of rays for star-convex polygon')\n",
        "plt.ylabel('Reconstruction score (mean IoU)')\n",
        "plt.title(\"Mean IoU of ground truth reconstruction (should be > 0.8 for a reasonable number of rays)\")\n",
        "None;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwO371VFSf61"
      },
      "source": [
        "# 2. Training \n",
        "\n",
        "\n",
        "Training data (for input `X` with associated label masks `Y`) can be provided via lists of numpy arrays, where each image can have a different size. Alternatively, a single numpy array can also be used if all images have the same size.  \n",
        "Input images can either be two-dimensional (single-channel) or three-dimensional (multi-channel) arrays, where the channel axis comes last. Label images need to be integer-valued."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZRk78lqSf61"
      },
      "source": [
        "fX = sorted(Path('data/dsb2018/train/images/').glob('*.tif'))\n",
        "fY = sorted(Path('data/dsb2018/train/masks').glob('*.tif'))\n",
        "assert all(Path(x).name==Path(y).name for x,y in zip(fX,fY))\n",
        "print(f\"{len(fX)} files found\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ_rITSjSf63"
      },
      "source": [
        "X = list(map(imread,map(str,tqdm(fX))))\n",
        "Y = list(map(imread,map(str,tqdm(fY))))\n",
        "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nM21GHKSf66"
      },
      "source": [
        "Normalize images and fill small label holes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0sSTDZ7Sf67"
      },
      "source": [
        "axis_norm = (0,1)   # normalize channels independently\n",
        "# axis_norm = (0,1,2) # normalize channels jointly\n",
        "if n_channel > 1:\n",
        "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
        "Y = [fill_label_holes(y) for y in tqdm(Y)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO3scWFrSf69"
      },
      "source": [
        "Split into train and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9PxV4maSf6-"
      },
      "source": [
        "assert len(X) > 1, \"not enough training data\"\n",
        "rng = np.random.RandomState(42)\n",
        "ind = rng.permutation(len(X))\n",
        "n_val = max(1, int(round(0.15 * len(ind))))\n",
        "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
        "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
        "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
        "print('number of images: %3d' % len(X))\n",
        "print('- training:       %3d' % len(X_trn))\n",
        "print('- validation:     %3d' % len(X_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21L1LHeUSf7A"
      },
      "source": [
        "Training data consists of pairs of input image and label instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNR7F44xSf7A"
      },
      "source": [
        "i = min(9, len(X)-1)\n",
        "img, lbl = X[i], Y[i]\n",
        "assert img.ndim in (2,3)\n",
        "img = img if img.ndim==2 else img[...,:3]\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(121); plt.imshow(img,cmap='gray');   plt.axis('off'); plt.title('Raw image')\n",
        "plt.subplot(122); plt.imshow(lbl,cmap=lbl_cmap, interpolation=\"nearest\"); plt.axis('off'); plt.title('GT labels')\n",
        "None;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC1nVB4OSf7D"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "A `StarDist2D` model is specified via a `Config2D` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLOA--2hSf7D"
      },
      "source": [
        "print(Config2D.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpJWGiR5Sf7I"
      },
      "source": [
        "conf = Config2D (\n",
        "    n_rays       = 32,\n",
        "    grid         = (2,2),\n",
        "    n_channel_in = 1,\n",
        ")\n",
        "print(conf)\n",
        "vars(conf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoyHjTItSf7N"
      },
      "source": [
        "**Note:** The trained `StarDist2D` model will *not* predict completed shapes for partially visible objects at the image boundary if `train_shape_completion=False` (which is the default option)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noQaZKbNSf7N"
      },
      "source": [
        "model = StarDist2D(conf, name='stardist', basedir='models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0bG10FUSf7P"
      },
      "source": [
        "Check if the neural network has a large enough field of view to see up to the boundary of most objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgl5kG6GSf7Q"
      },
      "source": [
        "median_size = calculate_extents(list(Y), np.median)\n",
        "fov = np.array(model._axes_tile_overlap('YX'))\n",
        "if any(median_size > fov):\n",
        "    print(\"WARNING: median object size larger than field of view of the neural network.\")\n",
        "else:\n",
        "    print(\"All good! (object sizes fit into field of view of the neural network)\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkDWPwB50sam"
      },
      "source": [
        "## Pretrained Models\n",
        "\n",
        "The following command can be used to show a list of available pretrained models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiVxmww103vB"
      },
      "source": [
        "StarDist2D.from_pretrained()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzguGqwISf7T"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09l9UNQ2Sf7T"
      },
      "source": [
        "\n",
        "You can define a function/callable that applies augmentation to each batch of the data generator.  \n",
        "We here use an `augmenter` that applies random rotations, flips, and intensity changes, which are typically sensible for (2D) microscopy images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4SYL3wXSf7U"
      },
      "source": [
        "def random_fliprot(img, mask): \n",
        "    axes = tuple(range(img.ndim)) \n",
        "    perm = np.random.permutation(axes)\n",
        "    img = img.transpose(perm) \n",
        "    mask = mask.transpose(perm) \n",
        "    for ax in axes: \n",
        "        if np.random.rand()>.5:\n",
        "            img = np.flip(img,axis = ax)\n",
        "            mask = np.flip(mask,axis = ax)\n",
        "    return img, mask \n",
        "\n",
        "def random_intensity_change(img):\n",
        "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-.2,.2)\n",
        "    return img\n",
        "\n",
        "\n",
        "def augmenter(img,mask):\n",
        "    \"\"\"Augmentation for image,mask\"\"\"\n",
        "    img, mask = random_fliprot(img, mask)\n",
        "    img = random_intensity_change(img)\n",
        "    return img, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLknrQ8n-eNu"
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.subplot(121); plt.imshow(img,cmap='gray', clim = (0,1));   plt.axis('off'); plt.title('Raw image')\n",
        "plt.subplot(122); plt.imshow(lbl,cmap=lbl_cmap, interpolation=\"nearest\"); plt.axis('off'); plt.title('GT labels (mask)')\n",
        "  \n",
        "for _ in range(4):\n",
        "    plt.figure(figsize=(8,5))\n",
        "    x,y = augmenter(img, lbl)\n",
        "    plt.subplot(121); plt.imshow(x,cmap='gray', clim = (0,1));   plt.axis('off'); plt.title('Augmented: Raw image')\n",
        "    plt.subplot(122); plt.imshow(y,cmap=lbl_cmap, interpolation=\"nearest\"); plt.axis('off'); plt.title('Augmented: GT labels (mask)')\n",
        "None;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY7FSf_9-vJ0"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9R4-D9W1TS9"
      },
      "source": [
        "We recommend to monitor the progress during training with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ0jr41NBHue"
      },
      "source": [
        "!rm -rf logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDuztcpR1Yq3"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=. --port 6008"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvouFU_ASf7W"
      },
      "source": [
        "quick_demo = True\n",
        "\n",
        "if quick_demo:\n",
        "    print (\n",
        "        \"NOTE: This is only for a quick demonstration!\\n\"\n",
        "        \"      Please set the variable 'quick_demo = False' for proper (long) training.\",\n",
        "        file=sys.stderr, flush=True\n",
        "    )\n",
        "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter,\n",
        "                epochs=40, steps_per_epoch=25)\n",
        "\n",
        "    print(\"====> Stopping training and loading previously trained demo model from disk.\", file=sys.stderr, flush=True)\n",
        "    model = StarDist2D.from_pretrained(\"2D_versatile_fluo\")\n",
        "else:\n",
        "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter)\n",
        "None;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TZRSgHBSf7Y"
      },
      "source": [
        "## Threshold optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxURfvjzSf7Y"
      },
      "source": [
        "While the default values for the probability and non-maximum suppression thresholds already yield good results in many cases, we still recommend to adapt the thresholds to your data. The optimized threshold values are saved to disk and will be automatically loaded with the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyiOl6vFSf7Y",
        "scrolled": false
      },
      "source": [
        "if not quick_demo:\n",
        "    model.optimize_thresholds(X_val, Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9i_Uc0Vhkmo"
      },
      "source": [
        "# 3. Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFqM_nfISf7b"
      },
      "source": [
        "We now load images from the sub-folder `test` that have not been used during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F1dxPkjSf7c"
      },
      "source": [
        "fXt = sorted(Path('data/dsb2018/test/images/').glob('*.tif'))\n",
        "print(f\"{len(fXt)} files found\")\n",
        "Xt = list(map(imread,map(str,tqdm(fXt))))\n",
        "\n",
        "n_channel = 1 if Xt[0].ndim == 2 else Xt[0].shape[-1]\n",
        "axis_norm = (0,1)   # normalize channels independently\n",
        "# axis_norm = (0,1,2) # normalize channels jointly\n",
        "if n_channel > 1:\n",
        "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVZvImXHSf7j"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "Make sure to normalize the input image beforehand or supply a `normalizer` to the prediction function.\n",
        "\n",
        "Calling `model.predict_instances` will\n",
        "- predict object probabilities and star-convex polygon distances (see `model.predict` if you want those)\n",
        "- perform non-maximum suppression (with overlap threshold `nms_thresh`) for polygons above object probability threshold `prob_thresh`.\n",
        "- render all remaining polygon instances in a label image\n",
        "- return the label instances image and also the details (coordinates, etc.) of all remaining polygons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlC5U0QPSf7k"
      },
      "source": [
        "img = normalize(Xt[16], 1,99.8, axis=axis_norm)\n",
        "labels, details = model.predict_instances(img, verbose = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsbTTP5bSf7m"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(img if img.ndim==2 else img[...,:3], clim=(0,1), cmap='gray')\n",
        "plt.imshow(labels, cmap=lbl_cmap, interpolation=\"nearest\", alpha=0.5)\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyLLSfoASf7o"
      },
      "source": [
        "## More example results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx35cI3ASf7p"
      },
      "source": [
        "def example(model, i, show_dist=True):\n",
        "    img = normalize(Xt[i], 1,99.8, axis=axis_norm)\n",
        "    labels, details = model.predict_instances(img)\n",
        "\n",
        "    plt.figure(figsize=(13,10))\n",
        "    img_show = img if img.ndim==2 else img[...,:3]\n",
        "    coord, points, prob = details['coord'], details['points'], details['prob']\n",
        "    plt.subplot(121); plt.imshow(img_show, cmap='gray'); plt.axis('off')\n",
        "    a = plt.axis()\n",
        "    _draw_polygons(coord, points, prob, show_dist=show_dist)\n",
        "    plt.axis(a)\n",
        "    plt.subplot(122); plt.imshow(img_show, cmap='gray'); plt.axis('off')\n",
        "    plt.imshow(labels, cmap=lbl_cmap, interpolation=\"nearest\", alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuB0Iq-5Sf7q"
      },
      "source": [
        "example(model, 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1saqzu_CSf7s"
      },
      "source": [
        "example(model, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftpjFsbuSf7t"
      },
      "source": [
        "example(model, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbD17JNyMrsw"
      },
      "source": [
        "## Evaluation and Detection Performance\n",
        "\n",
        "Besides the losses and metrics during training, we can also quantitatively evaluate the actual detection/segmentation performance on the validation data by considering objects in the ground truth to be correctly matched if there are predicted objects with overlap (here [intersection over union (IoU)](https://en.wikipedia.org/wiki/Jaccard_index)) beyond a chosen IoU threshold $\\tau$.\n",
        "\n",
        "The corresponding matching statistics (average overlap, accuracy, recall, precision, etc.) are typically of greater practical relevance than the losses/metrics computed during training (but harder to formulate as a loss function). \n",
        "The value of $\\tau$ can be between 0 (even slightly overlapping objects count as correctly predicted) and 1 (only pixel-perfectly overlapping objects count) and which $\\tau$ to use depends on the needed segmentation precision/application.\n",
        "\n",
        "Please see the Wikipedia page on [Sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) for definitions of the abbreviations used in the evaluation below. Note that `mean_true_score` refers to the average overlap (IoU) of all true positives (tp), i.e. correctly predicted objects in terms of the chosen overlap threshold.\n",
        "\n",
        "First predict the labels for all validation images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Ir85f2MrXp"
      },
      "source": [
        "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
        "              for x in tqdm(X_val)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDgMAw5sM2cJ"
      },
      "source": [
        "Choose several IoU thresholds $\\tau$ that might be of interest and for each compute matching statistics for the validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooj6e66eM10X"
      },
      "source": [
        "taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=False) for t in tqdm(taus)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WZVsRcyM6Eo"
      },
      "source": [
        "Example: Print all available matching statistics for $\\tau=0.5$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kovhf4reM8bs"
      },
      "source": [
        "stats[taus.index(0.5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zldGIgddNAmH"
      },
      "source": [
        "Plot the matching statistics and the number of true/false positives/negatives as a function of the IoU threshold $\\tau$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xjwSMeZNAFk"
      },
      "source": [
        "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n",
        "\n",
        "for m in ('precision', 'recall', 'accuracy', 'f1', 'mean_true_score'):\n",
        "    ax1.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
        "ax1.set_xlabel(r'IoU threshold $\\tau$')\n",
        "ax1.set_ylabel('Metric value')\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "\n",
        "for m in ('fp', 'tp', 'fn'):\n",
        "    ax2.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
        "ax2.set_xlabel(r'IoU threshold $\\tau$')\n",
        "ax2.set_ylabel('Number #')\n",
        "ax2.grid()\n",
        "ax2.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RO8YeRzSf7u"
      },
      "source": [
        "## Export your model to Fiji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGkaFVQDSf7v"
      },
      "source": [
        "if not quick_demo:\n",
        "    model.export_TF()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}